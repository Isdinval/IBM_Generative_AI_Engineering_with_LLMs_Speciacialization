# Exploring Generative AI Libraries

![Generative AI](https://img.shields.io/badge/Generative-AI-blue) ![Transformers](https://img.shields.io/badge/Transformers-HuggingFace-orange)

This repository contains a hands-on lab exploring generative AI libraries, focusing on transformer-based models for building chatbots. The lab covers foundational concepts, real-world applications, and practical implementations using Hugging Face's `transformers` library.

## Lab Overview

### Objectives
By the end of this lab, you will:
- Understand generative AI and its impact across domains like art, NLP, and computer vision.
- Learn about different generative models, including N-grams, RNNs, LSTMs, and transformers.
- Build and interact with a chatbot using transformer models from Hugging Face.

### Key Topics
1. **Generative AI Fundamentals**
   - Definition and real-world applications (art, NLP, computer vision, virtual avatars).
2. **Text Generation Models**
   - Evolution from N-grams and RNNs to transformers.
   - Attention mechanisms and the transformer architecture.
3. **Hands-on Implementation**
   - Building a chatbot using `facebook/blenderbot-400M-distill` and `google/flan-t5-base`.
   - Comparing outputs of different models.

### Prerequisites
- Python 3.12+
- Libraries: `transformers`, `torch`, `sentencepiece`, `numpy`
